## COLLECTING THE DATA From Wikipedia using Beautiful Soup ##
#
#Import the required packages
!pip3 install beautifulsoup4
!pip3 install requests
import sys
import requests
from bs4 import BeautifulSoup
import re
import unicodedata
import pandas as pd

#Next build some helper functions to process web scraped HTML tables

#This function returns the date and time from the HTML table cell
#Input: the element of a table data cell extracts extra row
def date_time(table_cells):
    return [data_time.strip() for data_time in list(table_cells.strings)][0:2]

#This function returns the booster version from the HTML table cell
#Input: the element of a table data cell extracts extra row
def booster_version(table_cells):
    out=''.join([booster_version for i,booster_version in enumerate( table_cells.strings) if i%2==0][0:-1])
    return out

#This function returns the landing status from the HTML table cell
#Input: the element of a table data cell extracts extra row
def landing_status(table_cells):
    out=[i for i in table_cells.strings][0]
    return out


def get_mass(table_cells):
    mass=unicodedata.normalize("NFKD", table_cells.text).strip()
    if mass:
        mass.find("kg")
        new_mass=mass[0:mass.find("kg")+2]
    else:
        new_mass=0
    return new_mass

#This function returns the landing status from the HTML table cell
#Input: the element of a table data cell extracts extra row
def extract_column_from_header(row):
    if (row.br):
        row.br.extract()
    if row.a:
        row.a.extract()
    if row.sup:
        row.sup.extract()
        
    colunm_name = ' '.join(row.contents)
    
    # Filter the digit and empty names
    if not(colunm_name.strip().isdigit()):
        colunm_name = colunm_name.strip()
        return colunm_name    

#To keep the project consistent, I was asked to scrape the data from a snapshot of the: 
#List of Falcon 9 and Falcon Heavy launches wikipiage updated on 9th June 2021
static_url = "https://en.wikipedia.org/w/index.php?title=List_of_Falcon_9_and_Falcon_Heavy_launches&oldid=1027686922"

#Now request the HTML page from the url set above, and create a BeautifulSoup object from the response
response = requests.get(static_url)
soup = BeautifulSoup(response.content)

#Print the page title to verify the object was created properly
print(soup.title)

#The next step is to extract all column/variable names from the HTML table header

#Lets try to find all tables on the wiki page
html_tables = soup.find_all('table')

#Starting from the 3rd table because thats the table that has the launch records
first_launch_table = html_tables[2]

#Next I have to iterate through the <th> elements and use the extract_column_from_header() function 
#to retrieve the column names one by one and append the non empty column name
column_names = []
th_array = first_launch_table.find_all('th')
for th_element in th_array:
    name = extract_column_from_header(th_element)
    if name is not None and len(name)>0:
        column_names.append(name)

#Check the column names to see if theyve been successfully imported
print(column_names)

# Now we have to create a data frame by parsing the launch HTML tables
#We'll create an empty dictionary with keys from the extracted column names

launch_dict= dict.fromkeys(column_names)

# Remove an irrelvant column
del launch_dict['Date and time ( )']

# Let's initial the launch_dict with each value to be an empty list
launch_dict['Flight No.'] = []
launch_dict['Launch site'] = []
launch_dict['Payload'] = []
launch_dict['Payload mass'] = []
launch_dict['Orbit'] = []
launch_dict['Customer'] = []
launch_dict['Launch outcome'] = []
# Added some new columns
launch_dict['Version Booster']=[]
launch_dict['Booster landing']=[]
launch_dict['Date']=[]
launch_dict['Time']=[]

#Next we just need to fill up the launch_dict with the records weve extracted
extracted_row = 0
#Extract each table 
for table_number,table in enumerate(soup.find_all('table',"wikitable plainrowheaders collapsible")):
   # get table row 
    for rows in table.find_all("tr"):
        #check to see if first table heading is as number corresponding to launch a number 
        if rows.th:
            if rows.th.string:
                flight_number=rows.th.string.strip()
                flag=flight_number.isdigit()
        else:
            flag=False
        #get table element 
        row=rows.find_all('td')
        #if it is number save cells in a dictonary 
        if flag:
            extracted_row += 1
            # Flight Number value
            datatimelist=date_time(row[0])
            launch_dict['Flight No.'].append(flight_number)
            
            # Date value
            date = datatimelist[0].strip(',')
            launch_dict['Date'].append(date)
            
            # Time value
            time = datatimelist[1]
            launch_dict['Time'].append(time)
              
            # Booster version
            bv=booster_version(row[1])
            if not(bv):
                bv=row[1].a.string
            launch_dict['Version Booster'].append(bv)
            
            # Launch Site
            launch_site = row[2].a.string
            launch_dict['Launch site'].append(launch_site)
            
            # Payload
            payload = row[3].a.string
            launch_dict['Payload'].append(payload)
            
            # Payload Mass
            payload_mass = get_mass(row[4])
            launch_dict['Payload mass'].append(payload_mass)
            
            # Orbit
            orbit = row[5].a.string
            launch_dict['Orbit'].append(orbit)
            
            # Customer
            customer = row[6]
            launch_dict['Customer'].append(customer)
            
            # Launch outcome
            launch_outcome = list(row[7].strings)[0]
            launch_dict['Launch outcome'].append(launch_outcome)
            
            # Booster landing
            booster_landing = landing_status(row[8])
            launch_dict['Booster landing'].append(booster_landing)

#After filling in the parsed launch record values we can create a dataframe from it and save it for later use
df = pd.DataFrame(launch_dict)
df.to_csv('spacex_web_scraped.csv', index=False)
